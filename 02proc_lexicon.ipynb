{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Process large Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROC_DATA_PREFIX = '/Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  381171 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lexicon40\n",
      "kesia \t мбе\n",
      "antoine \t антуан\n",
      "mindua \t миндуа\n",
      "participation \t россии\n",
      "partner \t партнера\n",
      "russia \t россии\n"
     ]
    }
   ],
   "source": [
    "# Look at data\n",
    "!wc -l {PROC_DATA_PREFIX}/lexicon40\n",
    "!head -3 {PROC_DATA_PREFIX}/lexicon40\n",
    "!tail -3 {PROC_DATA_PREFIX}/lexicon40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and remove duplicate lines\n",
    "!sort -u {PROC_DATA_PREFIX}/lexicon40 > {PROC_DATA_PREFIX}/lexicon_sort_uniq40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58241 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lexicon_sort_uniq40\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {PROC_DATA_PREFIX}/lexicon_sort_uniq40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines where SRC == TRG\n",
    "with open(PROC_DATA_PREFIX + '/' + 'lexicon_sort_uniq40', 'r', encoding='utf8') as inF, \\\n",
    "     open(PROC_DATA_PREFIX + '/' + 'lexicon_sort_uniq_nonequal40', 'w', encoding='utf8') as toF:\n",
    "    for line in inF:\n",
    "        line_list = line.split('\\t')\n",
    "        src_str, trg_str = line_list[0].strip(), line_list[1].strip()\n",
    "        if src_str != trg_str:\n",
    "            toF.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58161 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lexicon_sort_uniq_nonequal40\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {PROC_DATA_PREFIX}/lexicon_sort_uniq_nonequal40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove lines where SRC ~= TRG\n",
    "import nltk\n",
    "from nltk.metrics.distance import jaro_similarity\n",
    "\n",
    "# Count all similarity scores\n",
    "with open(PROC_DATA_PREFIX + '/' + 'lexicon_sort_uniq_nonequal40', 'r', encoding='utf8') as inF, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lex_sim_scores.txt', 'w', encoding='utf8') as toF_fuzzy:\n",
    "    for line in inF:\n",
    "        line_list = line.split('\\t')\n",
    "        src_str, trg_str = line_list[0].strip(), line_list[1].strip()\n",
    "        jaro_sim = jaro_similarity(src_str, trg_str)\n",
    "        toF_fuzzy.write(str(jaro_sim) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58161 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lex_sim_scores.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l {PROC_DATA_PREFIX}/'lex_sim_scores.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58161\n",
      "     832 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lex_above_45_sim40.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Look at highly similar items \n",
    "with open(PROC_DATA_PREFIX + '/' + 'lex_sim_scores.txt', 'r', encoding='utf8') as inF_scores, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lexicon_sort_uniq_nonequal40', 'r', encoding='utf8') as inF_text, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lex_above_45_sim40.txt', 'w', encoding='utf8') as toF_text:\n",
    "    simil_scores = [float(s) for s in inF_scores]\n",
    "    print(len(simil_scores))\n",
    "    for i, line in enumerate(inF_text):\n",
    "        if simil_scores[i] > 0.45:\n",
    "            toF_text.write(line)\n",
    "\n",
    "!wc -l {PROC_DATA_PREFIX}/'lex_above_45_sim40.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th \t 10го\n",
      "131st \t 131м\n",
      "17th \t 17м\n",
      "18th \t 18й\n",
      "1980s \t 1980х\n",
      "1b \t 1в\n",
      "252nd \t 252го\n",
      "2nd \t 2я\n",
      "2x9 \t 2х9\n",
      "319th \t 319м\n",
      "required \t мнсi\n",
      "res \t r\n",
      "sensitivity \t gsinas\n",
      "set \t rev\n",
      "statement \t prst\n",
      "statute \t ter\n",
      "terms \t mutandis\n",
      "tribunal \t ter\n",
      "use \t подтвeрждая\n",
      "with \t bis\n"
     ]
    }
   ],
   "source": [
    "# This is what I am going to remove from Flossary\n",
    "!head {PROC_DATA_PREFIX}/'lex_above_45_sim40.txt'\n",
    "!tail {PROC_DATA_PREFIX}/'lex_above_45_sim40.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58161\n",
      "   57329 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lex_preproc40\r\n"
     ]
    }
   ],
   "source": [
    "# Keep only dissimilar items\n",
    "threshold = 0.45  # similarity score\n",
    "with open(PROC_DATA_PREFIX + '/' + 'lex_sim_scores.txt', 'r', encoding='utf8') as inF_scores, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lexicon_sort_uniq_nonequal40', 'r', encoding='utf8') as inF_text, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lex_preproc40', 'w', encoding='utf8') as toF_text:\n",
    "    simil_scores = [float(s) for s in inF_scores]\n",
    "    print(len(simil_scores))\n",
    "    for i, line in enumerate(inF_text):\n",
    "        if simil_scores[i] < threshold:\n",
    "            toF_text.write(line)\n",
    "\n",
    "!wc -l {PROC_DATA_PREFIX}/'lex_preproc40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   56460 /Users/alexskrn/Documents/NLP/WordAlign/wordalign_notebooks/data/lex_preproc40_cleaned\r\n"
     ]
    }
   ],
   "source": [
    "# remove more extraneous elements, digits\n",
    "stopwords = ['--']\n",
    "digits_set = set('0123456789')\n",
    "with open(PROC_DATA_PREFIX + '/' + 'lex_preproc40', 'r', encoding='utf8') as inF, \\\n",
    "    open(PROC_DATA_PREFIX + '/' + 'lex_preproc40_cleaned', 'w', encoding='utf8') as toF:\n",
    "    for line in inF:\n",
    "        line_list = line.split('\\t')\n",
    "        src_str, trg_str = line_list[0].strip(), line_list[1].strip()\n",
    "        if  (len(src_str) > 1) \\\n",
    "            and (len(src_str) > 1) \\\n",
    "            and (len(set(src_str) & digits_set) == 0) \\\n",
    "            and (len(set(trg_str) & digits_set) == 0) \\\n",
    "            and (trg_str not in stopwords):\n",
    "            toF.write(line)\n",
    "\n",
    "!wc -l {PROC_DATA_PREFIX}/'lex_preproc40_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
